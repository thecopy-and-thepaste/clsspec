{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create our work dataset from two other ones. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Domain dataset, which contains species names from GBIF site.\n",
    "\n",
    "Out-of-domain dataset, with general knowlegde texts in plain-text files. For this example, we use abstracts from the PLOS site, but feel free to replace it with another files.\n",
    "\n",
    "Then, we draw some insights to create our model and the text handling. Such as, size of the samples, quantity, stategy, etc.\n",
    "\n",
    "We also use the <a href=\"https://bitbucket.org/conabio_cmd/conabio_ml_text\">CONABIO ML Text</a> library to template an end-to-end pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pydash\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use the CONABIO_ML library code always remember to update your PYTHONPATH env variable with\n",
    "# export PYTHONPATH=`pwd`:`pwd`/conabio_ml_text/conabio_ml:`pwd`/conabio_ml_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conabio_ml_text.datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the dataset using two types of samples: species names and common knowledge words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_path = Path(\"dataset\")\n",
    "\n",
    "d_dataset_path = base_dataset_path / \"species.txt\"\n",
    "ood_dataset_path = base_dataset_path / \"text_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain specific dataset is a plain text file (<i>We assume it located at `base_dataset_path / \"species.txt\"` </i>) that contains taxonomic trees of species, with the following format:\n",
    "\n",
    "`species_parent, species, … `.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We obtained this dataset from the <a href=\"https://www.gbif.org/developer/species\">GBIF species API</a> using `Animalia` as a root taxonomic tree. \n",
    "\n",
    "You can gather the json representations of the taxonomic tree, and then convert it to plain text, according to your needs using the `dataset_builder.py` script.\n",
    "\n",
    "You can download the text file for this example, from <a href=\"https://tctp-datasets.s3.us-south.cloud-object-storage.appdomain.cloud/species.txt\">HERE</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bulimina_algethica</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pachyspirillina_involutinoides</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plectogyra_nana</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nodosaria_conspecies</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nummulites_suboenotria</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>isnella_misiki</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>odontogriphidae</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10064</th>\n",
       "      <td>quinqueloculina_adriatica</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10065</th>\n",
       "      <td>nummulites_batalleri</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10066</th>\n",
       "      <td>lepidocyclina_collinsi</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 item    label\n",
       "0                  bulimina_algethica  species\n",
       "1      pachyspirillina_involutinoides  species\n",
       "2                     plectogyra_nana  species\n",
       "3                nodosaria_conspecies  species\n",
       "4              nummulites_suboenotria  species\n",
       "...                               ...      ...\n",
       "10062                  isnella_misiki  species\n",
       "10063                 odontogriphidae  species\n",
       "10064       quinqueloculina_adriatica  species\n",
       "10065            nummulites_batalleri  species\n",
       "10066          lepidocyclina_collinsi  species\n",
       "\n",
       "[10067 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_names = \"\"\n",
    "with open(d_dataset_path) as _f:\n",
    "    species_names = _f.read()\n",
    "    \n",
    "species_trees = species_names.split(\"\\n\")\n",
    "species = set(pydash.chain(species_trees)\\\n",
    "              .filter(lambda x: len(x) > 0)\\\n",
    "              .map(lambda x: x.lower().split(\",\"))\\\n",
    "              .flatten()\\\n",
    "              .map(lambda x: x.replace(\" \", \"_\"))\\\n",
    "              .value())\n",
    "\n",
    "domain_dataset = pd.DataFrame(list(species), columns = [\"item\"])\n",
    "domain_dataset[\"label\"] = \"species\"\n",
    "domain_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10067"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(domain_dataset[\"item\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we draw some basic insights of the d-dataset (domain dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Mean char size of species: 19. Max char size of species: 49'\n",
      "'Mean word size of species: 1. Max word size of species: 1'\n",
      "'Dataset size: 10067'\n"
     ]
    }
   ],
   "source": [
    "species_lengths = domain_dataset[\"item\"].apply(lambda x: len(x))\n",
    "species_words = domain_dataset[\"item\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "MEAN_SPECIES_SIZE = int(np.mean(species_lengths))\n",
    "pprint(f\"Mean char size of species: {MEAN_SPECIES_SIZE}. Max char size of species: {np.max(species_lengths)}\")\n",
    "\n",
    "MEAN_SPECIES_WORDS = int(np.mean(species_words))\n",
    "pprint(f\"Mean word size of species: {MEAN_SPECIES_WORDS}. Max word size of species: {np.max(species_words)}\")\n",
    "\n",
    "\n",
    "pprint(f\"Dataset size: {len(domain_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, at word level. We have the number of unique tokens in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'And we have 10067 unique species words.'\n"
     ]
    }
   ],
   "source": [
    "word_level = pydash.chain(domain_dataset[\"item\"])\\\n",
    "            .map(lambda x: set(x.split()))\\\n",
    "            .reduce(lambda x, y: x.union(y), set())\\\n",
    "            .value()\n",
    "\n",
    "pprint(f\"And we have {len(word_level)} unique species words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "For the non-domain dataset, we use a set of `1000` abstracts with subject `health sciences` obtained from the  <a href=\"https://plos.org/\">PLOS site</a>.  Gathered using the <a href=\"https://github.com/thecopy-and-thepaste/qtod\">qtod module</a>.\n",
    "\n",
    "You can use your own plain text files or just download the files we are working with from <a href=\">SS\">HERE</a>, and extract it. We assume the path for the files in `base_dataset_path / \"text_files\"`.\n",
    "\n",
    "Then, we just extract 1-3 grams taking care that samples don't repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_numbers = re.compile('^[-+]?[\\d.]+(?:e-?\\d+)?$')\n",
    "\n",
    "def ood_preproc(item_path:str):\n",
    "    try:\n",
    "        with open (item_path, mode=\"r\", encoding='utf-8') as _f:\n",
    "            item = _f.read()\n",
    "\n",
    "        tokens = []\n",
    "        # We only care to remove hyperlink, puntuation, and numbers.\n",
    "        item = item.lower()\n",
    "\n",
    "        item = item.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "\n",
    "        for token in item.split():               \n",
    "            if re.findall(re_numbers, token):\n",
    "                continue\n",
    "\n",
    "            tokens.append(token)\n",
    "\n",
    "        ix = 0\n",
    "        while ix < len(tokens):\n",
    "            step = random.randint(1, 3)\n",
    "\n",
    "            yield \"_\".join(tokens[ix: ix+step])\n",
    "            ix += step\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        print(item_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:39:48,083 [conabio_ml.datasets.dataset] [DEBUG]  Creating dataset with 114186 registers\n",
      "2021-02-15 15:39:48,118 [conabio_ml.datasets.dataset] [DEBUG]  Dataset with ordinal labels\n",
      "2021-02-15 15:39:48,278 [conabio_ml.datasets.dataset] [DEBUG]  1 categories in dataset\n",
      "2021-02-15 15:39:48,279 [conabio_ml.datasets.dataset] [INFO ]  Assigning labelmap with [{0: PosixPath('non_species')}]\n"
     ]
    }
   ],
   "source": [
    "ood = Dataset.from_folder(source_path=ood_dataset_path,\n",
    "                          extensions=[\"txt\"],\n",
    "                          recursive=False,\n",
    "                          label_by_folder_name=True,\n",
    "                          split_by_folder=False,\n",
    "                          include_id=False,\n",
    "                          item_reader = ood_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sapovirus_is_a</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genus_of</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caliciviruses</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71300</th>\n",
       "      <td>ppf3_could_classically</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71301</th>\n",
       "      <td>activate_macrophages</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71302</th>\n",
       "      <td>induction_may_be</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71303</th>\n",
       "      <td>manner_in</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71304</th>\n",
       "      <td>polysaccharides</td>\n",
       "      <td>non_species</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         item        label\n",
       "0              sapovirus_is_a  non_species\n",
       "1                    genus_of  non_species\n",
       "2               caliciviruses  non_species\n",
       "3                        that  non_species\n",
       "4                         are  non_species\n",
       "...                       ...          ...\n",
       "71300  ppf3_could_classically  non_species\n",
       "71301    activate_macrophages  non_species\n",
       "71302        induction_may_be  non_species\n",
       "71303               manner_in  non_species\n",
       "71304         polysaccharides  non_species\n",
       "\n",
       "[71002 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_items = ood.data[\"item\"].unique()\n",
    "ood_dataset = pd.DataFrame(ood_items, columns=[\"item\"])\n",
    "ixs = ood_dataset.apply(lambda x: len(x[\"item\"]) >= 3, axis = 1)\n",
    "\n",
    "ood_dataset = ood_dataset.loc[ixs]\n",
    "ood_dataset[\"label\"] = \"non_species\"\n",
    "ood_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, just drop as a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([ood_dataset, domain_dataset])\n",
    "dataset.reset_index(drop=True)\n",
    "dataset.to_csv(base_dataset_path / \"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81069, 81069)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(ood_dataset[\"item\"].unique()) + len(domain_dataset[\"item\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
